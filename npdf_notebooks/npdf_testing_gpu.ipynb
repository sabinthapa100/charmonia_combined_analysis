{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eeff62c4",
   "metadata": {},
   "source": [
    "## Centrality Dependence of CNM Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd3f4a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<CUDA Device 0>\n"
     ]
    }
   ],
   "source": [
    "# CUDA 12.x example\n",
    "# !pip install -U cupy-cuda12x\n",
    "import cupy as cp; x=cp.arange(5); print(x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89dde03c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'npdf_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mxp_array\u001b[39m(a, **kw): \u001b[38;5;28;01mreturn\u001b[39;00m np.asarray(a, **kw)\n\u001b[32m     15\u001b[39m     GPU = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnpdf_data\u001b[39;00m\u001b[38;5;250m   \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NPDFSystem, RpAAnalysis\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgluon_ratio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EPPS21Ratio, GluonEPPSProvider\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mglauber\u001b[39;00m\u001b[38;5;250m     \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpticalGlauber, SystemSpec\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'npdf_data'"
     ]
    }
   ],
   "source": [
    "# npdf_gpu_pipeline.py\n",
    "# Fast, GPU-aware (CuPy) RpA driver for RAW + BINNED + HESSIAN bands.\n",
    "from __future__ import annotations\n",
    "import numpy as np\n",
    "try:\n",
    "    import cupy as cp\n",
    "    XP = cp                         # GPU\n",
    "    def xp_asnumpy(a): return cp.asnumpy(a)\n",
    "    def xp_array(a, **kw): return cp.asarray(a, **kw)\n",
    "    GPU = True\n",
    "except Exception:\n",
    "    XP = np                         # CPU fallback\n",
    "    def xp_asnumpy(a): return np.asarray(a)\n",
    "    def xp_array(a, **kw): return np.asarray(a, **kw)\n",
    "    GPU = False\n",
    "\n",
    "from npdf_data   import NPDFSystem, RpAAnalysis\n",
    "from gluon_ratio import EPPS21Ratio, GluonEPPSProvider\n",
    "from glauber     import OpticalGlauber, SystemSpec\n",
    "\n",
    "# --------- small utils ---------\n",
    "def _pairwise_hessian_band(vals49: np.ndarray, axis=0, cl68=False):\n",
    "    \"\"\"\n",
    "    vals49: shape (..., 49, ...), index 0 = central, 1..48 = error members in EPPS pair order\n",
    "    Returns (central, lo, hi) along 'axis', using symmetric Hessian (90% CL).\n",
    "    \"\"\"\n",
    "    # move 'axis' to the front for convenience\n",
    "    v = np.moveaxis(vals49, axis, 0)   # [49, ...]\n",
    "    c = v[0]\n",
    "    diffsq = 0.0\n",
    "    # pairs: (2,3), (4,5), ... (48,49)  -> 1-based -> 1..48 zero-based: (1,2),(3,4),...\n",
    "    for k in range(1, 49, 2):\n",
    "        d = v[k] - v[k+1]\n",
    "        diffsq = diffsq + d*d\n",
    "    delta90 = 0.5 * np.sqrt(diffsq)\n",
    "    delta = delta90 / 1.645 if cl68 else delta90\n",
    "    return c, c - delta, c + delta\n",
    "\n",
    "def _weighted_avg_perbin(values, weights, bin_idx, nbins):\n",
    "    \"\"\"\n",
    "    values: (..., N)  (can be 49 sets x N or 1 x N)\n",
    "    weights: (N,)\n",
    "    bin_idx: (N,) int64 in [0..nbins-1] or -1 for out of range\n",
    "    returns (..., nbins)\n",
    "    \"\"\"\n",
    "    # reshape to [M, N]\n",
    "    M = int(values.shape[0])\n",
    "    N = int(values.shape[-1])\n",
    "    vals = values.reshape(M, N)\n",
    "\n",
    "    # mask out-of-range\n",
    "    valid = bin_idx >= 0\n",
    "    if GPU:\n",
    "        valid_idx = XP.where(valid)[0]\n",
    "    else:\n",
    "        valid_idx = np.where(valid)[0]\n",
    "    if valid_idx.size == 0:\n",
    "        return XP.zeros((M, nbins), dtype=values.dtype)\n",
    "\n",
    "    idx = bin_idx[valid_idx]\n",
    "    w   = weights[valid_idx]\n",
    "    v   = vals[:, valid_idx]            # [M, Nv]\n",
    "\n",
    "    # numerator/denominator using bincount; loop M (49) is cheap\n",
    "    out = XP.zeros((M, nbins), dtype=values.dtype)\n",
    "    den = XP.bincount(idx, weights=w, minlength=nbins)\n",
    "    den = XP.maximum(den, XP.asarray(1e-30, den.dtype))\n",
    "    for m in range(M):\n",
    "        num = XP.bincount(idx, weights=v[m]*w, minlength=nbins)\n",
    "        out[m] = num / den\n",
    "    return out\n",
    "\n",
    "def _bin_edges(start, stop, step):\n",
    "    # robust edges inclusive of 'stop'\n",
    "    n = int(np.floor((stop - start) / step + 1e-12)) + 1\n",
    "    return np.linspace(start, start + n*step, n+1)\n",
    "\n",
    "# --------- core loaders (CPU) ---------\n",
    "def load_R0_and_weights(top_folder: str):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      base_df           : DataFrame with (y, pt)\n",
    "      R0_sets_49xN      : np.ndarray float64\n",
    "      sigma_pA_central  : np.ndarray float64 weights aligned to base_df\n",
    "    \"\"\"\n",
    "    ana = RpAAnalysis()\n",
    "    sys = NPDFSystem.from_folder(top_folder, kick=\"pp\")\n",
    "    base, r0_central, M = ana.compute_rpa_members(sys.df_pp, sys.df_pa, sys.df_errors, join=\"intersect\")\n",
    "    R0 = np.vstack([r0_central[None, :], M])   # [49, N]\n",
    "    # weights = σ_pA^central aligned to base grid\n",
    "    wtab = ana._make_weight_table(base.assign(r_central=r0_central), sys.df_pa, df_pp=sys.df_pp, mode=\"pa\")\n",
    "    w = wtab[\"w\"].to_numpy(float)              # [N]\n",
    "    return base, R0.astype(np.float64), w.astype(np.float64)\n",
    "\n",
    "def precompute_SA_sets(provider: GluonEPPSProvider, yv: np.ndarray, pv: np.ndarray):\n",
    "    \"\"\"\n",
    "    Compute and cache gluon S_A for all 49 sets on the (y,pt) grid.\n",
    "    Returns SA_sets: [49, N]\n",
    "    \"\"\"\n",
    "    SA = np.empty((49, yv.size), dtype=np.float64)\n",
    "    for sid in range(1, 50):    # 1..49\n",
    "        SA[sid-1] = np.asarray(provider.SA_ypt_set(yv, pv, set_id=sid, flav=\"g\"), float)\n",
    "    return SA\n",
    "\n",
    "def K_sets_from_alpha(SA_49xN: np.ndarray, alpha_bar: float, Nnorm: float):\n",
    "    \"\"\"\n",
    "    K = (1 + Nnorm*(S_A-1)*alpha_bar) / S_A  → shape [49, N]\n",
    "    \"\"\"\n",
    "    SA = SA_49xN\n",
    "    num = 1.0 + Nnorm * (SA - 1.0) * float(alpha_bar)\n",
    "    den = np.clip(SA, 1e-15, None)\n",
    "    return num / den\n",
    "\n",
    "# --------- high-level reports ---------\n",
    "class NPDFGPUDriver:\n",
    "    def __init__(self, *,\n",
    "                 pPb_dir: str,\n",
    "                 epps_dir: str,\n",
    "                 sqrt_sNN_GeV: float,\n",
    "                 sigmaNN_mb: float = 71.0,\n",
    "                 A: int = 208,\n",
    "                 m_state: str | float = \"charmonium\",\n",
    "                 y_sign_for_xA: int = -1):\n",
    "        # 1) R0 & weights (CPU)\n",
    "        self.base, self.R0_49xN, self.wN = load_R0_and_weights(pPb_dir)\n",
    "        self.y = self.base[\"y\"].to_numpy(float)\n",
    "        self.pt = self.base[\"pt\"].to_numpy(float)\n",
    "        # 2) EPPS gluon provider + geometry (CPU)\n",
    "        self.provider = GluonEPPSProvider(\n",
    "            EPPS21Ratio(A=A, path=epps_dir),\n",
    "            sqrt_sNN_GeV=float(sqrt_sNN_GeV),\n",
    "            m_state_GeV=m_state,\n",
    "            y_sign_for_xA=y_sign_for_xA\n",
    "        ).with_geometry(None)\n",
    "        self.geom = self.provider._geom\n",
    "        self.Nnorm = float(self.geom.Nnorm())\n",
    "        self.sigmaNN_mb = float(sigmaNN_mb)\n",
    "\n",
    "        # 3) Precompute S_A for all sets on the grid (CPU, cached)\n",
    "        self.SA_49xN = precompute_SA_sets(self.provider, self.y, self.pt)\n",
    "\n",
    "        # 4) Move big arrays to GPU (if available)\n",
    "        self.R0_x = xp_array(self.R0_49xN)\n",
    "        self.SA_x = xp_array(self.SA_49xN)\n",
    "        self.w_x  = xp_array(self.wN)\n",
    "\n",
    "    # ---------- MIN-BIAS (K=1) ----------\n",
    "    def rpa_mb_raw(self):\n",
    "        \"\"\"RAW min-bias: returns R0 for all sets on the unbinned (y,pt) points.\"\"\"\n",
    "        return self.R0_x  # [49, N], central in row 0\n",
    "\n",
    "    # ---------- CENTRALITY ----------\n",
    "    def rpa_vs_centrality(self, cent_edges=(0,20,40,60,80,100),\n",
    "                          y_rng=(-5,5), pt_rng=(0,20)):\n",
    "        \"\"\"\n",
    "        Weighted average over chosen (y,pt) window, reported per centrality bin.\n",
    "        Returns dict with keys 'cent_left', 'central', 'lo', 'hi'.\n",
    "        \"\"\"\n",
    "        y0, y1 = float(y_rng[0]), float(y_rng[1])\n",
    "        p0, p1 = float(pt_rng[0]), float(pt_rng[1])\n",
    "        sel = (self.y >= y0) & (self.y < y1) & (self.pt >= p0) & (self.pt < p1)\n",
    "        if not np.any(sel):\n",
    "            return dict(cent_left=np.asarray([]), central=np.asarray([]), lo=np.asarray([]), hi=np.asarray([]))\n",
    "\n",
    "        # slice grid\n",
    "        R0 = self.R0_x[:, sel]      # [49, Ns]\n",
    "        SA = self.SA_x[:, sel]      # [49, Ns]\n",
    "        w  = self.w_x[sel]          # [Ns]\n",
    "\n",
    "        # build alpha_bar per bin from Glauber (CPU; scalar per bin)\n",
    "        cent_edges = list(cent_edges)\n",
    "        out_vals = []\n",
    "        for i in range(len(cent_edges)-1):\n",
    "            cL, cR = cent_edges[i], cent_edges[i+1]\n",
    "            a_bar = float(self.geom.alpha_bar_for_bin(cL, cR, sigmaNN_mb=self.sigmaNN_mb))\n",
    "            K = xp_array(K_sets_from_alpha(xp_asnumpy(SA), a_bar, self.Nnorm))   # compute on CPU, send to GPU\n",
    "            R = R0 * K  # [49, Ns]\n",
    "            # weighted average over the slice\n",
    "            num = XP.sum(R * w, axis=1)   # [49]\n",
    "            den = XP.sum(w) + XP.asarray(1e-30)\n",
    "            mean_per_set = num / den      # [49]\n",
    "            out_vals.append(mean_per_set)\n",
    "\n",
    "        # shape → [nbins, 49] → numpy\n",
    "        V = xp_asnumpy(XP.stack(out_vals, axis=0))  # [B, 49]\n",
    "        # Hessian per bin\n",
    "        central, lo, hi = [], [], []\n",
    "        for b in range(V.shape[0]):\n",
    "            c, l, h = _pairwise_hessian_band(V[b, :][None, ...], axis=1)  # feed [1,49]\n",
    "            central.append(float(c.ravel()[0])); lo.append(float(l.ravel()[0])); hi.append(float(h.ravel()[0]))\n",
    "        return dict(\n",
    "            cent_left=np.asarray(cent_edges[:-1], float),\n",
    "            central=np.asarray(central, float),\n",
    "            lo=np.asarray(lo, float),\n",
    "            hi=np.asarray(hi, float),\n",
    "        )\n",
    "\n",
    "    # ---------- BINNED vs y (min-bias, then bands) ----------\n",
    "    def rpa_vs_y(self, y_edges=np.arange(-5.0, 5.0+1e-9, 0.5), pt_rng=(0,20)):\n",
    "        p0, p1 = float(pt_rng[0]), float(pt_rng[1])\n",
    "        sel = (self.pt >= p0) & (self.pt < p1)\n",
    "        R0 = self.R0_x[:, sel]     # [49, Ns]\n",
    "        w  = self.w_x[sel]\n",
    "        yy = XP.asarray(self.y[sel])\n",
    "        # bin index\n",
    "        be = XP.asarray(y_edges)\n",
    "        # digitize half-open [left,right)\n",
    "        idx = XP.digitize(yy, be) - 1\n",
    "        # set out-of-range to -1\n",
    "        idx = XP.where((idx >= 0) & (idx < (len(y_edges)-1)), idx, -1)\n",
    "        # per-bin weighted means per set\n",
    "        means = _weighted_avg_perbin(R0, w, idx, nbins=len(y_edges)-1)  # [49, Nybins]\n",
    "        V = xp_asnumpy(means)   # numpy\n",
    "        # Hessian per bin\n",
    "        C, L, H = _pairwise_hessian_band(V, axis=0)  # bins along axis 1 → pass axis=0 after our shape\n",
    "        return dict(y_left=np.asarray(y_edges[:-1], float), central=C, lo=L, hi=H)\n",
    "\n",
    "    # ---------- BINNED vs pT (min-bias, then bands) ----------\n",
    "    def rpa_vs_pt(self, pt_edges=np.arange(0.0, 20.0+1e-9, 2.5), y_rng=(-5,5)):\n",
    "        y0, y1 = float(y_rng[0]), float(y_rng[1])\n",
    "        sel = (self.y >= y0) & (self.y < y1)\n",
    "        R0 = self.R0_x[:, sel]     # [49, Ns]\n",
    "        w  = self.w_x[sel]\n",
    "        pp = XP.asarray(self.pt[sel])\n",
    "        be = XP.asarray(pt_edges)\n",
    "        idx = XP.digitize(pp, be) - 1\n",
    "        idx = XP.where((idx >= 0) & (idx < (len(pt_edges)-1)), idx, -1)\n",
    "        means = _weighted_avg_perbin(R0, w, idx, nbins=len(pt_edges)-1)  # [49, Npbins]\n",
    "        V = xp_asnumpy(means)\n",
    "        C, L, H = _pairwise_hessian_band(V, axis=0)\n",
    "        return dict(pt_left=np.asarray(pt_edges[:-1], float), central=C, lo=L, hi=H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a1b486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- inputs (edit to your paths/energies) ---\n",
    "P5   = \"./input/npdf/pPb5TeV\"\n",
    "P8   = \"./input/npdf/pPb8TeV\"\n",
    "EPPS = \"./input/npdf/nPDFs\"\n",
    "\n",
    "# 5.02 TeV\n",
    "drv5 = NPDFGPUDriver(pPb_dir=P5, epps_dir=EPPS, sqrt_sNN_GeV=5023.0, sigmaNN_mb=67.2, A=208)\n",
    "\n",
    "# 8.16 TeV\n",
    "drv8 = NPDFGPUDriver(pPb_dir=P8, epps_dir=EPPS, sqrt_sNN_GeV=8160.0, sigmaNN_mb=71.0,  A=208)\n",
    "\n",
    "CENT_EDGES = (0,20,40,60,80,100)\n",
    "Y_EDGES    = np.arange(-5.0, 5.0+1e-9, 0.5)\n",
    "PT_EDGES   = np.arange( 0.0,20.0+1e-9, 2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382095f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) RpA vs centrality (choose a rapidity/pT window, e.g. midrapidity, all pT)\n",
    "r_cent_5 = drv5.rpa_vs_centrality(CENT_EDGES, y_rng=(-1.37,0.43), pt_rng=(0,20))\n",
    "r_cent_8 = drv8.rpa_vs_centrality(CENT_EDGES, y_rng=(-1.37,0.43), pt_rng=(0,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8198dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) RpA vs y (min-bias) in 0–20 GeV\n",
    "r_y_5 = drv5.rpa_vs_y(Y_EDGES, pt_rng=(0,20))\n",
    "r_y_8 = drv8.rpa_vs_y(Y_EDGES, pt_rng=(0,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34642fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) RpA vs pT (min-bias) in three y-windows (example)\n",
    "mid = drv5.rpa_vs_pt(PT_EDGES, y_rng=(-1.37,0.43))\n",
    "fwd = drv5.rpa_vs_pt(PT_EDGES, y_rng=( 2.03,3.53))\n",
    "bwd = drv5.rpa_vs_pt(PT_EDGES, y_rng=(-4.46,-2.96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39c459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) RAW (no binning): per (y,pt) grid, all 49 sets (min-bias baseline)\n",
    "R0_raw_5 = drv5.rpa_mb_raw()  # shape [49, N] aligned to drv5.base[['y','pt']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323488eb",
   "metadata": {},
   "source": [
    "## Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633fd332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step2_rpa_vs_centrality.py\n",
    "from __future__ import annotations\n",
    "import numpy as np\n",
    "try:\n",
    "    import cupy as cp\n",
    "    xp = cp\n",
    "    GPU = True\n",
    "except Exception:\n",
    "    xp = np\n",
    "    GPU = False\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple, List, Dict, Sequence\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89216707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- small helpers ----\n",
    "def _to_xp(a):\n",
    "    return xp.asarray(a) if not isinstance(a, xp.ndarray) else a\n",
    "\n",
    "def _to_np(a):\n",
    "    return cp.asnumpy(a) if GPU and isinstance(a, cp.ndarray) else np.asarray(a)\n",
    "\n",
    "def _bin_widths(b: np.ndarray) -> np.ndarray:\n",
    "    b = np.asarray(b, float)\n",
    "    if b.size == 1:\n",
    "        return np.array([1.0], float)\n",
    "    dx = np.empty_like(b)\n",
    "    dx[1:-1] = 0.5*(b[2:] - b[:-2])\n",
    "    dx[0]    = 0.5*(b[1] - b[0])\n",
    "    dx[-1]   = 0.5*(b[-1] - b[-2])\n",
    "    return dx\n",
    "\n",
    "def _hessian_band(values49: xp.ndarray) -> Tuple[xp.ndarray, xp.ndarray, xp.ndarray]:\n",
    "    \"\"\"\n",
    "    values49: shape (49, ...) with [0]=central, [1..48]=Hessian members in (−,+) pairs\n",
    "    Returns (central, lo, hi) with symmetric Hessian at 68%CL (EPPS21 default is 90% — rescale if you want).\n",
    "    \"\"\"\n",
    "    C = values49[0]\n",
    "    # members are assumed to be ordered as (2,3), (4,5), ..., (48,49) in 1-based EPPS → here (1,2), (3,4), ...\n",
    "    diffsq = xp.zeros_like(C)\n",
    "    for k in range(1, 49, 2):\n",
    "        dm = values49[k]   # \"minus\"\n",
    "        dp = values49[k+1] # \"plus\"\n",
    "        diffsq = diffsq + (dp - dm)**2\n",
    "    d90 = 0.5 * xp.sqrt(diffsq)\n",
    "    d68 = d90 / 1.645   # convert 90%→68% if you prefer 68% CL\n",
    "    return C, C - d68, C + d68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5f2dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CentralityBin:\n",
    "    tag: str\n",
    "    bL: float\n",
    "    bR: float\n",
    "    w_b: np.ndarray     # weights on your raw b-grid, normalized inside [bL,bR]\n",
    "\n",
    "def centrality_bins_from_glauber(glb, b_grid: np.ndarray, edges_pct: Sequence[float]) -> List[CentralityBin]:\n",
    "    \"\"\"\n",
    "    Map centrality percent edges → (b_L, b_R), then build inelastic weights over your discrete b-grid.\n",
    "    \"\"\"\n",
    "    # 1) get CDF arrays from Glauber\n",
    "    cum = glb.cum_pA           # cumulative P_inel(b) normalized to 1\n",
    "    bG  = glb.b_grid           # fine Glauber b grid (0..~20 fm)\n",
    "    # 2) inverse CDF for each edge\n",
    "    def b_at_percent(pct):\n",
    "        c = float(pct)/100.0\n",
    "        return float(np.interp(c, _to_np(cum), _to_np(bG)))\n",
    "    # 3) inelastic weight density ~ 2π b (1 - exp(-σ T(b))) — use Glauber’s arrays\n",
    "    #    We approximate on your discrete b_grid by interpolating TpA(b) to those points.\n",
    "    sigma_fm2 = glb.sigma_nn_mb * 0.1\n",
    "    TpA_at_raw = np.interp(b_grid, _to_np(glb.b_grid), _to_np(glb.TpA_b))\n",
    "    Pinel = 1.0 - np.exp(-sigma_fm2 * np.maximum(TpA_at_raw, 0.0))\n",
    "    db = _bin_widths(b_grid)\n",
    "    base_w = 2.0*np.pi*b_grid*db*Pinel\n",
    "    bins: List[CentralityBin] = []\n",
    "    for i in range(len(edges_pct)-1):\n",
    "        L, R = b_at_percent(edges_pct[i]), b_at_percent(edges_pct[i+1])\n",
    "        m = (b_grid >= L) & (b_grid < R)\n",
    "        w = base_w * m\n",
    "        s = w.sum()\n",
    "        w = w/s if s > 0 else w\n",
    "        bins.append(CentralityBin(f\"{edges_pct[i]}-{edges_pct[i+1]}%\", L, R, w))\n",
    "    return bins\n",
    "\n",
    "def average_over_b_sets(R_49byp: xp.ndarray, w_b: np.ndarray) -> xp.ndarray:\n",
    "    \"\"\"\n",
    "    R_49byp: (49, Nb, Ny, Np)\n",
    "    w_b:     (Nb,) numpy weights (will be moved to xp)\n",
    "    returns: (49, Ny, Np)  weighted average over b\n",
    "    \"\"\"\n",
    "    W = _to_xp(w_b.reshape(1, -1, 1, 1))\n",
    "    num = xp.sum(R_49byp * W, axis=1)\n",
    "    # W sums to 1 within the bin by construction → denominator=1\n",
    "    return num\n",
    "\n",
    "def average_over_ypt_sets(R_49yp: xp.ndarray,\n",
    "                          y_grid: np.ndarray, pt_grid: np.ndarray,\n",
    "                          y_win: Tuple[float,float],\n",
    "                          pt_win: Tuple[float,float],\n",
    "                          sigma_pa_central: np.ndarray) -> xp.ndarray:\n",
    "    \"\"\"\n",
    "    R_49yp: (49, Ny, Np)\n",
    "    sigma_pa_central: (Ny, Np) weights (pp is acceptable too; we use σ_pA central by default)\n",
    "    returns: (49,) weighted average over (y, pT)\n",
    "    \"\"\"\n",
    "    y = np.asarray(y_grid); p = np.asarray(pt_grid)\n",
    "    mY = (y >= y_win[0]) & (y <= y_win[1])\n",
    "    mP = (p >= pt_win[0]) & (p <= pt_win[1])\n",
    "    if not mY.any() or not mP.any():\n",
    "        return xp.full((49,), xp.nan)\n",
    "\n",
    "    # slice\n",
    "    R = R_49yp[:, mY][:, :, mP]               # (49, nY, nP)\n",
    "    W = _to_xp(np.clip(sigma_pa_central[mY][:, mP], 0, None))\n",
    "    s = xp.sum(W)\n",
    "    if s <= 0:\n",
    "        return xp.full((49,), xp.nan)\n",
    "    return xp.sum(R * W, axis=(1,2)) / s\n",
    "\n",
    "def rpa_vs_centrality_with_band(raw: Dict,\n",
    "                                glb,                        # OpticalGlauber instance (matching energy)\n",
    "                                sigma_pa_central: np.ndarray,  # (Ny, Np) from your npdf_data sys.df_pa central\n",
    "                                edges_pct=(0,20,40,60,80,100),\n",
    "                                y_win=(-5,5), pt_win=(0,20)) -> Dict:\n",
    "    \"\"\"\n",
    "    Compute: for each centrality bin → 49-set RpA averaged over b (bin) and then over (y,pT),\n",
    "    plus a min-bias (0–100%) horizontal band.\n",
    "    Returns dict with arrays ready to plot: centers (%), (r_c, r_lo, r_hi), and MB band.\n",
    "    \"\"\"\n",
    "    # unpack raw\n",
    "    b_grid = np.asarray(raw[\"b\"], float)\n",
    "    y_grid = np.asarray(raw[\"y\"], float)\n",
    "    p_grid = np.asarray(raw[\"pt\"], float)\n",
    "    R      = _to_xp(raw[\"R\"])                 # (49, Nb, Ny, Np)\n",
    "\n",
    "    # centrality bins (weights on your b_grid)\n",
    "    cbins = centrality_bins_from_glauber(glb, b_grid, edges_pct)\n",
    "\n",
    "    # per-bin 49-set averages\n",
    "    r49_per_bin = []\n",
    "    for C in cbins:\n",
    "        R_49yp = average_over_b_sets(R, C.w_b)                # (49, Ny, Np)\n",
    "        r49 = average_over_ypt_sets(R_49yp, y_grid, p_grid, y_win, pt_win, sigma_pa_central)\n",
    "        r49_per_bin.append(_to_np(r49))                       # (49,)\n",
    "\n",
    "    r49_per_bin = np.stack(r49_per_bin, axis=0)               # (Nbin, 49)\n",
    "    # build Hessian band per bin\n",
    "    rc, rlo, rhi = [], [], []\n",
    "    for i in range(r49_per_bin.shape[0]):\n",
    "        C, L, H = _hessian_band(_to_xp(r49_per_bin[i]))\n",
    "        rc.append(_to_np(C)); rlo.append(_to_np(L)); rhi.append(_to_np(H))\n",
    "    rc, rlo, rhi = map(np.asarray, (rc, rlo, rhi))            # (Nbin,)\n",
    "\n",
    "    # min-bias (0–100%) once\n",
    "    Cmb = centrality_bins_from_glauber(glb, b_grid, (0,100))[0]\n",
    "    Rmb_49yp = average_over_b_sets(R, Cmb.w_b)                # (49, Ny, Np)\n",
    "    rmb_49   = _to_np(average_over_ypt_sets(Rmb_49yp, y_grid, p_grid, y_win, pt_win, sigma_pa_central))\n",
    "    Cmb_c, Cmb_lo, Cmb_hi = map(_to_np, _hessian_band(_to_xp(rmb_49)))\n",
    "\n",
    "    # x (bin centers in %)\n",
    "    cent_edges = np.asarray(edges_pct, float)\n",
    "    cent_mid   = 0.5*(cent_edges[:-1] + cent_edges[1:])\n",
    "\n",
    "    return dict(\n",
    "        cent_mid=cent_mid, cent_edges=cent_edges,\n",
    "        r_c=rc, r_lo=rlo, r_hi=rhi,\n",
    "        mb_c=float(Cmb_c), mb_lo=float(Cmb_lo), mb_hi=float(Cmb_hi)\n",
    "    )\n",
    "\n",
    "# --------- tiny plot helper (matplotlib) ----------\n",
    "def plot_vs_centrality(res_5, res_8, title=\"\", note=\"\", outfile=None):\n",
    "    import matplotlib.pyplot as plt\n",
    "    def _stairs(x_left, y):\n",
    "        x = np.asarray(x_left, float)\n",
    "        dx = np.diff(x); dx_last = dx[-1] if dx.size else 20.0\n",
    "        return np.r_[x, x[-1]+dx_last], np.r_[y, y[-1]]\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6.8, 4.2), constrained_layout=True)\n",
    "    for res, color, lab in [(res_5, \"tab:blue\", \"5.02 TeV\"), (res_8, \"tab:red\", \"8.16 TeV\")]:\n",
    "        xL = res[\"cent_edges\"][:-1]\n",
    "        for y, lo, hi, label in [(res[\"r_c\"], res[\"r_lo\"], res[\"r_hi\"], fr\"{lab}\")]:\n",
    "            X, Yc = _stairs(xL, y); _, Ylo = _stairs(xL, lo); _, Yhi = _stairs(xL, hi)\n",
    "            ax.step(X, Yc, where=\"post\", lw=2, color=color, label=label)\n",
    "            ax.fill_between(X, Ylo, Yhi, step=\"post\", alpha=0.25, color=color)\n",
    "        # min-bias band (horizontal)\n",
    "        ax.axhspan(res[\"mb_lo\"], res[\"mb_hi\"], alpha=0.18, color=color, lw=0)\n",
    "        ax.axhline(res[\"mb_c\"], color=color, ls=\"--\", lw=1.4, alpha=0.9)\n",
    "\n",
    "    ax.set_xlabel(\"Centrality [%]\"); ax.set_ylabel(r\"$R_{pA}$\")\n",
    "    ax.set_xlim(0, 100); ax.set_ylim(0.35, 1.25)\n",
    "    if note: ax.text(0.02, 0.02, note, transform=ax.transAxes, ha=\"left\", va=\"bottom\",\n",
    "                     bbox=dict(facecolor=\"white\", alpha=0.85, edgecolor=\"none\"))\n",
    "    ax.legend(frameon=False)\n",
    "    if title: ax.set_title(title)\n",
    "    if outfile:\n",
    "        Path(outfile).parent.mkdir(parents=True, exist_ok=True)\n",
    "        fig.savefig(outfile, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6211ebc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In your notebook/session right after Step 1 (where raw5/raw8 are built):\n",
    "from glauber import OpticalGlauber, SystemSpec\n",
    "from npdf_data import NPDFSystem   \n",
    "\n",
    "# --- Glauber per energy (σ_NN mb that you already use) ---\n",
    "glb5 = OpticalGlauber(SystemSpec(system=\"pA\", roots_GeV=5023.0, A=208, sigma_nn_mb=67.2), verbose=False)\n",
    "glb8 = OpticalGlauber(SystemSpec(system=\"pA\", roots_GeV=8160.0, A=208, sigma_nn_mb=71.0),  verbose=False)\n",
    "\n",
    "# --- σ_pA central weights on the SAME (y,pt) grid you used to make raw tables ---\n",
    "sys5 = NPDFSystem.from_folder(\"./input/npdf/pPb5TeV\", kick=\"pp\")\n",
    "sys8 = NPDFSystem.from_folder(\"./input/npdf/pPb8TeV\", kick=\"pp\")\n",
    "\n",
    "# Build a σ_pA(y,pt) central weight grid aligned to raw's (y,pt):\n",
    "def sigma_pa_central_on_raw_grid(sysX, rawX):\n",
    "    # nearest-neighbor remap is fine because your raw grid was built from these same slabs\n",
    "    # make a tiny map from (y,pt)->σ\n",
    "    from collections import defaultdict\n",
    "    tab = defaultdict(dict)\n",
    "    for y,pt,val in sysX.df_pa[[\"y\",\"pt\",\"val\"]].to_numpy():\n",
    "        tab[float(y)][float(pt)] = float(val)\n",
    "    yv, pv = rawX[\"y\"], rawX[\"pt\"]\n",
    "    Y, P = np.meshgrid(yv, pv, indexing=\"ij\")\n",
    "    W = np.empty_like(Y, float)\n",
    "    for i, yy in enumerate(yv):\n",
    "        row = tab.get(float(yy), {})\n",
    "        # fallback: nearest pt by min |Δpt|\n",
    "        pts_row = np.array(list(row.keys())) if row else np.array([pv[0]])\n",
    "        for j, pp in enumerate(pv):\n",
    "            if pp in row:\n",
    "                W[i,j] = row[pp]\n",
    "            else:\n",
    "                jn = int(np.argmin((pts_row-pp)**2))\n",
    "                W[i,j] = row.get(pts_row[jn], 0.0)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f905f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06cca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "W5 = sigma_pa_central_on_raw_grid(sys5, raw5)  # shape (Ny, Np)\n",
    "W8 = sigma_pa_central_on_raw_grid(sys8, raw8)\n",
    "\n",
    "# --- choose windows & bins ---\n",
    "CENT_EDGES = (0,20,40,60,80,100)\n",
    "Y_WINDOWS  = [(-4.46,-2.96), (-1.37,0.43), (2.03,3.53)]\n",
    "PT_RANGE   = (0.0, 20.0)  # change to (2.5,20) etc.\n",
    "\n",
    "# --- make the 3-window figure (call once per window or loop) ---\n",
    "for y_win, tag in zip(Y_WINDOWS, [\"Backward\",\"Mid\",\"Forward\"]):\n",
    "    res5 = rpa_vs_centrality_with_band(raw5, glb5, W5, CENT_EDGES, y_win=y_win, pt_win=PT_RANGE)\n",
    "    res8 = rpa_vs_centrality_with_band(raw8, glb8, W8, CENT_EDGES, y_win=y_win, pt_win=PT_RANGE)\n",
    "    plot_vs_centrality(\n",
    "        res5, res8,\n",
    "        title=f\"RpA vs Centrality — {tag} rapidity\",\n",
    "        note=fr\"{y_win[0]} < y < {y_win[1]},  {PT_RANGE[0]} ≤ $p_T$ ≤ {PT_RANGE[1]} GeV\",\n",
    "        outfile=f\"./output-npdf/step2_rpa_vs_centrality_{tag}.pdf\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
